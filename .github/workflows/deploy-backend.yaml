name: Deploy Backend to Hugging Face Space

on:
  push:
    branches:
      - main
      - master
  workflow_dispatch:

jobs:
  sync-to-hub:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          lfs: true

      - name: Setup Git LFS
        run: |
          git lfs install
          git lfs pull
          git lfs checkout

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install huggingface_hub
        run: pip install huggingface_hub httpx

      - name: Push to Hugging Face Space
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python -c "
          from huggingface_hub import HfApi, login
          import os
          import time
          import httpx

          token = os.environ['HF_TOKEN']
          login(token=token)

          # Configure much longer timeout for large uploads
          os.environ['HF_HUB_DOWNLOAD_TIMEOUT'] = '600'
          os.environ['HTTPX_TIMEOUT'] = '600'

          api = HfApi()

          # Extensive ignore patterns to reduce upload size
          ignore_patterns = [
              # Python/Node
              '*.pyc', '__pycache__', '.git', '.git/**', 'node_modules', 'node_modules/**',
              '.venv', '.venv/**', '*.log', '.env',
              # Data files (regenerable)
              '*.parquet', '*.npy', '*.csv',
              # Artifacts (training intermediates)
              '**/Artifacts/**', '**/artifacts/data_*/**',
              # GitHub workflows (not needed on HF)
              '.github/**',
              # Frontend node modules
              'frontend/node_modules/**',
              # Temp/cache
              '*.tmp', '*.cache', '**/__pycache__/**',
              # Browser data
              '**/.browser_data/**', '**/ShaderCache/**', '**/GraphiteDawnCache/**',
              # Model caches (BERT etc - download at runtime)
              '**/models_cache/**',
              # Logs
              'logs/**', '*.log',
          ]

          # Retry logic with exponential backoff
          max_retries = 5
          for attempt in range(max_retries):
              try:
                  print(f'Attempt {attempt + 1}/{max_retries}...')
                  api.upload_folder(
                      folder_path='.',
                      repo_id='nivakaran/modelx',
                      repo_type='space',
                      token=token,
                      ignore_patterns=ignore_patterns,
                      commit_message='Deploy from GitHub Actions'
                  )
                  print('✅ Successfully pushed to Hugging Face Space!')
                  break
              except Exception as e:
                  if attempt < max_retries - 1:
                      wait_time = (2 ** attempt) * 60  # 60s, 120s, 240s, 480s
                      print(f'⚠️ Attempt {attempt + 1} failed: {e}')
                      print(f'Retrying in {wait_time}s...')
                      time.sleep(wait_time)
                  else:
                      print(f'❌ All {max_retries} attempts failed.')
                      raise e
          "

      - name: Verify Sync
        if: success()
        run: echo "✅ Successfully synced to Hugging Face Space!"

      - name: Sync Failed  
        if: failure()
        run: echo "❌ Failed to sync. Check if the Space exists at https://huggingface.co/spaces/nivakaran/modelx"

